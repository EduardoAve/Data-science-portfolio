# Sentiment Analysis on IMDB Movie Reviews (Baseline Implementation)

## Project Overview

This project implements a baseline model for **sentiment analysis** on the dataset of 50,000 IMDB movie reviews. The objective is to automatically classify a review as **positive** or **negative**.

A simplified text preprocessing approach and a Logistic Regression model are used as a starting point to evaluate the feasibility of classification. This project demonstrates the fundamental steps of an NLP workflow, including data loading, basic text cleaning, TF-IDF vectorization, and evaluation of a classification model.

## Motivation

Sentiment analysis is a crucial task in NLP with broad applications, such as:
* Monitoring public opinion on products, brands, or events.
* Filtering and prioritizing customer feedback.
* Understanding the reception of movies, books, or other media.
* Powering recommendation systems.

This project serves as a practical introduction to text classification and establishes a baseline upon which more complex models can be built.

## Data Source

* **Dataset:** IMDB Dataset of 50K Movie Reviews
* **Original Source (Example):** Kaggle - [https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews) (Verify this is the exact source you used).
* **Loading Method:** The associated notebook (`nlp_sentiment_analysis.ipynb` - *adjust name if different*) uses manual file upload via the Google Colab interface. An input file named `IMDB Dataset.csv` is expected.

## Simplified Methodology

The workflow followed in this baseline implementation was:

1.  **Data Loading:** Loading the CSV file using `pandas`, handling potential formatting errors (`engine='python'`, `escapechar='\\'`).
2.  **Initial Inspection:** Verifying the DataFrame structure, data types, null values, and class distribution (positive/negative).
3.  **Basic Text Preprocessing:**
    * Conversion to lowercase.
    * Removal of HTML tags.
    * Removal of non-alphabetic characters (keeping spaces).
    * Removal of extra whitespace.
    * *(Note: Advanced NLTK steps like specific tokenization, stopword removal, and lemmatization/stemming were omitted in this version due to technical difficulties encountered during development).*
4.  **Train/Test Split:** Splitting the data into training (75%) and test (25%) sets, stratified by sentiment.
5.  **TF-IDF Vectorization:** Converting the preprocessed text into numerical vectors using `TfidfVectorizer`, considering unigrams and bigrams (`ngram_range=(1, 2)`) and limiting the vocabulary to 7500 features. Built-in English stopword removal was applied by the vectorizer.
6.  **Baseline Model Training:** Training a **Logistic Regression** model on the vectorized training data.
7.  **Evaluation:** Measuring the model's performance on the test set using Accuracy, Confusion Matrix, and Classification Report (Precision, Recall, F1-Score).

## Baseline Results

* The baseline **Logistic Regression** model achieved notably good performance even with the simplified preprocessing.
* **Key Metrics:**
    * Accuracy: ~0.891 (89.1%)
    * F1-Score (Negative): ~0.890
    * F1-Score (Positive): ~0.892
* The balanced performance across both classes (similar F1-scores) suggests the model is not overly biased towards one class, despite not using advanced imbalance handling techniques (the original dataset was balanced).
* Feature importance was not calculated for this simple baseline model.

## Visualizations

The notebook includes basic visualizations to understand the data:
* Distribution of length (characters) and word count of the processed reviews.
* Boxplots comparing length/word count between positive and negative reviews.

*(Note: Specific plots are generated by running the notebook.)*

## Technologies Used

* **Language:** Python (3.x)
* **Core Libraries:**
    * Pandas
    * NumPy
    * Scikit-learn (`TfidfVectorizer`, `LogisticRegression`, `train_test_split`, metrics)
    * Matplotlib & Seaborn (For EDA plots)
    * Re (Regular Expressions for cleaning)
* **Environment:** Google Colab / Jupyter Notebook

## Installation & Setup

1.  Clone the repository (or download the files).
2.  Ensure you have Python 3 installed.
3.  It is recommended to use a virtual environment:
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows use `venv\Scripts\activate`
    pip install -r requirements.txt
    ```
    *(Note: A `requirements.txt` file should be included in the project folder).*

## Usage

1.  Ensure the required libraries are installed (see Setup).
2.  Open the main notebook (e.g., `nlp_sentiment_analysis.ipynb` - *adjust name if needed*) in Google Colab or a local Jupyter environment.
3.  **If using Colab:** Upload the `IMDB Dataset.csv` file using the "Files" panel on the left.
    **If running locally:** Place the `IMDB Dataset.csv` file in the same directory as the notebook or update the path in the code.
4.  Run the notebook cells sequentially.
5.  Results, including evaluation metrics, will be displayed in the notebook's output.

---
